{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, applications, callbacks\n",
        "from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr, mean_squared_error as mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "CONFIG = {\n",
        "    \"TOTAL_IMAGES\": 2000,\n",
        "    \"NUM_TRAIN\": 1800,\n",
        "    \"NUM_TEST\": 200,\n",
        "    \"IMG_SIZE\": 128,\n",
        "    \"BATCH_SIZE\": 64,\n",
        "    \"EPOCHS_WARMUP\": 10,\n",
        "    \"EPOCHS_FINETUNE\": 30,\n",
        "    \"LEARNING_RATE\": 1e-4,\n",
        "    \"PROJECT_DIR\": \"./working_vgg_attention_ae_32x32\",\n",
        "    \"USE_AUGMENTATION\": True,\n",
        "    \"USE_ATTENTION\": True,\n",
        "}\n",
        "\n",
        "if not os.path.exists(CONFIG[\"PROJECT_DIR\"]):\n",
        "    os.makedirs(CONFIG[\"PROJECT_DIR\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_full = tfds.load('cats_vs_dogs', split='train', as_supervised=True)\n",
        "ds_full = ds_full.take(CONFIG['TOTAL_IMAGES'])\n",
        "\n",
        "ds_train = ds_full.take(CONFIG['NUM_TRAIN'])\n",
        "ds_val = ds_full.skip(CONFIG['NUM_TRAIN'])\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, [CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, image\n",
        "\n",
        "def augment(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    image = tf.image.random_saturation(image, lower=0.9, upper=1.1)\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_images = []\n",
        "val_labels = []\n",
        "for img, lbl in ds_val:\n",
        "    resized_img = tf.image.resize(img, [CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']])\n",
        "    val_images.append(resized_img.numpy())\n",
        "    val_labels.append(lbl.numpy())\n",
        "\n",
        "X_test = np.array(val_images)\n",
        "y_test = np.array(val_labels).reshape(-1, 1)\n",
        "X_test_normalized = X_test.astype('float32') / 255.0\n",
        "\n",
        "train_ds = ds_train.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "if CONFIG['USE_AUGMENTATION']:\n",
        "    train_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.cache().shuffle(1000).batch(CONFIG[\"BATCH_SIZE\"]).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = ds_val.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.batch(CONFIG[\"BATCH_SIZE\"]).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SpatialAttention(layers.Layer):\n",
        "    def __init__(self, channels, reduction=8, **kwargs):\n",
        "        super(SpatialAttention, self).__init__(**kwargs)\n",
        "        self.channels = channels\n",
        "        self.reduction = reduction\n",
        "        self.query_conv = layers.Conv2D(channels // reduction, 1, name='query')\n",
        "        self.key_conv = layers.Conv2D(channels // reduction, 1, name='key')\n",
        "        self.value_conv = layers.Conv2D(channels, 1, name='value')\n",
        "        self.gamma = self.add_weight(name='gamma', shape=(), initializer='zeros', trainable=True)\n",
        "    \n",
        "    def call(self, x):\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        height = tf.shape(x)[1]\n",
        "        width = tf.shape(x)[2]\n",
        "        \n",
        "        query = self.query_conv(x)\n",
        "        key = self.key_conv(x)\n",
        "        value = self.value_conv(x)\n",
        "        \n",
        "        query = tf.reshape(query, [batch_size, height * width, self.channels // self.reduction])\n",
        "        key = tf.reshape(key, [batch_size, height * width, self.channels // self.reduction])\n",
        "        value = tf.reshape(value, [batch_size, height * width, self.channels])\n",
        "        \n",
        "        attention_logits = tf.matmul(query, key, transpose_b=True)\n",
        "        scale = tf.cast(self.channels // self.reduction, tf.float32)\n",
        "        attention_logits = attention_logits / tf.sqrt(scale)\n",
        "        attention_weights = tf.nn.softmax(attention_logits, axis=-1)\n",
        "        \n",
        "        out = tf.matmul(attention_weights, value)\n",
        "        out = tf.reshape(out, [batch_size, height, width, self.channels])\n",
        "        \n",
        "        return x + self.gamma * out\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({'channels': self.channels, 'reduction': self.reduction})\n",
        "        return config\n",
        "\n",
        "\n",
        "class SSIMPSNRCallback(callbacks.Callback):\n",
        "    def __init__(self, validation_data, sample_size=200):\n",
        "        super().__init__()\n",
        "        self.validation_data = validation_data\n",
        "        self.sample_size = min(sample_size, len(validation_data))\n",
        "        self.ssim_history = []\n",
        "        self.psnr_history = []\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        indices = np.random.choice(len(self.validation_data), self.sample_size, replace=False)\n",
        "        sample_images = self.validation_data[indices]\n",
        "        predictions = self.model.predict(sample_images, verbose=0)\n",
        "        \n",
        "        ssim_scores = []\n",
        "        psnr_scores = []\n",
        "        for i in range(len(sample_images)):\n",
        "            s = ssim(sample_images[i], predictions[i], channel_axis=2, data_range=1.0)\n",
        "            p = psnr(sample_images[i], predictions[i], data_range=1.0)\n",
        "            ssim_scores.append(s)\n",
        "            psnr_scores.append(p)\n",
        "        \n",
        "        avg_ssim = np.mean(ssim_scores)\n",
        "        avg_psnr = np.mean(psnr_scores)\n",
        "        \n",
        "        self.ssim_history.append(avg_ssim)\n",
        "        self.psnr_history.append(avg_psnr)\n",
        "        \n",
        "        print(f\" - SSIM: {avg_ssim:.4f}, PSNR: {avg_psnr:.2f} dB\", end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_loss(y_true, y_pred):\n",
        "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
        "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
        "    return 0.7 * mse + 0.2 * mae + 0.1 * ssim_loss\n",
        "\n",
        "def build_model(mode='warmup'):\n",
        "    vgg = applications.VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "    encoder_output = vgg.get_layer('block2_pool').output\n",
        "    \n",
        "    x = layers.Conv2D(32, 1, padding='same', name='bottleneck')(encoder_output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    latent = layers.Activation('relu')(x)\n",
        "    encoder = models.Model(vgg.input, latent, name='encoder')\n",
        "    \n",
        "    decoder_input = layers.Input(shape=(8, 8, 32))\n",
        "    x = decoder_input\n",
        "    \n",
        "    x = layers.Conv2D(64, 3, padding='same', activation='relu', name='dec_conv1')(x)\n",
        "    if CONFIG['USE_ATTENTION']:\n",
        "        x = SpatialAttention(64, name='attention1')(x)\n",
        "    x = layers.UpSampling2D(2, name='up1')(x)\n",
        "    \n",
        "    x = layers.Conv2D(64, 3, padding='same', activation='relu', name='dec_conv2')(x)\n",
        "    if CONFIG['USE_ATTENTION']:\n",
        "        x = SpatialAttention(64, name='attention2')(x)\n",
        "    x = layers.UpSampling2D(2, name='up2')(x)\n",
        "    \n",
        "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
        "    decoder_output = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
        "    \n",
        "    decoder = models.Model(decoder_input, decoder_output, name='decoder')\n",
        "    autoencoder = models.Model(encoder.input, decoder(encoder.output), name='autoencoder')\n",
        "    \n",
        "    if mode == 'warmup':\n",
        "        encoder.trainable = False\n",
        "    else:\n",
        "        encoder.trainable = True\n",
        "        for layer in vgg.layers:\n",
        "            if 'block2' not in layer.name:\n",
        "                layer.trainable = False\n",
        "    \n",
        "    return autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import gc\n",
        "start_time = time.time()\n",
        "\n",
        "model = build_model(mode='warmup')\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=CONFIG['LEARNING_RATE']), loss=simple_loss)\n",
        "history_warmup = model.fit(train_ds, epochs=CONFIG['EPOCHS_WARMUP'], validation_data=test_ds, verbose=1)\n",
        "\n",
        "temp_weights = os.path.join(CONFIG[\"PROJECT_DIR\"], \"warmup_weights.weights.h5\")\n",
        "model.save_weights(temp_weights)\n",
        "\n",
        "del model\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = build_model(mode='finetune')\n",
        "model.load_weights(temp_weights)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "model.compile(optimizer=optimizer, loss=simple_loss)\n",
        "\n",
        "ckpt_path = os.path.join(CONFIG[\"PROJECT_DIR\"], \"best_model_attention.keras\")\n",
        "ssim_psnr_callback = SSIMPSNRCallback(X_test_normalized, sample_size=200)\n",
        "callbacks_list = [\n",
        "    ssim_psnr_callback,\n",
        "    callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1),\n",
        "    callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1),\n",
        "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(train_ds, epochs=CONFIG['EPOCHS_FINETUNE'], validation_data=test_ds, callbacks=callbacks_list, verbose=1)\n",
        "\n",
        "autoencoder = keras.models.load_model(ckpt_path, custom_objects={'simple_loss': simple_loss, 'SpatialAttention': SpatialAttention})\n",
        "elapsed = (time.time() - start_time) / 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_predictions = autoencoder.predict(X_test_normalized, batch_size=16, verbose=0)\n",
        "\n",
        "ssim_all = []\n",
        "psnr_all = []\n",
        "mse_all = []\n",
        "for i in range(len(X_test_normalized)):\n",
        "    ssim_score = ssim(X_test_normalized[i], test_predictions[i], channel_axis=2, data_range=1.0)\n",
        "    psnr_score = psnr(X_test_normalized[i], test_predictions[i], data_range=1.0)\n",
        "    mse_score = mse(X_test_normalized[i], test_predictions[i])\n",
        "    ssim_all.append(ssim_score)\n",
        "    psnr_all.append(psnr_score)\n",
        "    mse_all.append(mse_score)\n",
        "\n",
        "ssim_all = np.array(ssim_all)\n",
        "psnr_all = np.array(psnr_all)\n",
        "mse_all = np.array(mse_all)\n",
        "class_names = ['Cat', 'Dog']\n",
        "\n",
        "ssim_by_class = {}\n",
        "psnr_by_class = {}\n",
        "mse_by_class = {}\n",
        "for class_idx in range(2):\n",
        "    mask = (y_test.flatten() == class_idx)\n",
        "    ssim_by_class[class_idx] = ssim_all[mask]\n",
        "    psnr_by_class[class_idx] = psnr_all[mask]\n",
        "    mse_by_class[class_idx] = mse_all[mask]\n",
        "\n",
        "excellent_ssim = np.sum(ssim_all >= 0.85)\n",
        "excellent_psnr = np.sum(psnr_all >= 30)\n",
        "correlation = np.corrcoef(ssim_all, psnr_all)[0, 1]\n",
        "\n",
        "print(f\"Average SSIM: {np.mean(ssim_all):.4f}\")\n",
        "print(f\"Average PSNR: {np.mean(psnr_all):.2f} dB\")\n",
        "print(f\"Average MSE: {np.mean(mse_all):.6f}\")\n",
        "print(f\"Training time: {elapsed:.1f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "axes[0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(ssim_psnr_callback.ssim_history, linewidth=2, color='#3498db', marker='o')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('SSIM')\n",
        "axes[1].set_title('SSIM over Epochs (Fine-tuning)')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].plot(ssim_psnr_callback.psnr_history, linewidth=2, color='#e74c3c', marker='o')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('PSNR (dB)')\n",
        "axes[2].set_title('PSNR over Epochs (Fine-tuning)')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].hist(ssim_all, bins=50, alpha=0.7, edgecolor='black')\n",
        "axes[0].axvline(np.mean(ssim_all), color='red', linestyle='--', linewidth=2)\n",
        "axes[0].set_xlabel('SSIM Score')\n",
        "axes[0].set_title('SSIM Distribution')\n",
        "\n",
        "axes[1].hist(psnr_all, bins=50, alpha=0.7, edgecolor='black')\n",
        "axes[1].axvline(np.mean(psnr_all), color='red', linestyle='--', linewidth=2)\n",
        "axes[1].set_xlabel('PSNR (dB)')\n",
        "axes[1].set_title('PSNR Distribution')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "best_idx = np.argsort(ssim_all)[-5:][::-1]\n",
        "worst_idx = np.argsort(ssim_all)[:5]\n",
        "\n",
        "fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
        "for i, idx in enumerate(best_idx):\n",
        "    axes[0, i].imshow(X_test_normalized[idx])\n",
        "    axes[0, i].axis('off')\n",
        "    axes[1, i].imshow(test_predictions[idx])\n",
        "    axes[1, i].set_title(f'SSIM: {ssim_all[idx]:.3f}', color='green')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "for i, idx in enumerate(worst_idx):\n",
        "    axes[2, i].imshow(X_test_normalized[idx])\n",
        "    axes[2, i].axis('off')\n",
        "    axes[3, i].imshow(test_predictions[idx])\n",
        "    axes[3, i].set_title(f'SSIM: {ssim_all[idx]:.3f}', color='red')\n",
        "    axes[3, i].axis('off')\n",
        "\n",
        "plt.suptitle(f'Best and Worst Reconstructions (Avg SSIM: {np.mean(ssim_all):.4f})')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"\\nFINAL RESULTS:\")\n",
        "print(f\"   Average SSIM: {np.mean(ssim_all):.4f}\")\n",
        "print(f\"   Average PSNR: {np.mean(psnr_all):.2f} dB\")\n",
        "print(f\"   Average MSE: {np.mean(mse_all):.6f}\")\n",
        "print(f\"   Excellent images (â‰¥0.85): {excellent_ssim} ({excellent_ssim/len(ssim_all)*100:.1f}%)\")\n",
        "print(f\"   Training time: {elapsed:.1f} minutes ({elapsed/60:.2f} hours)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "cat_mask = (y_test.flatten() == 0)\n",
        "dog_mask = (y_test.flatten() == 1)\n",
        "\n",
        "axes[0, 0].bar(['Cat', 'Dog'], [np.mean(ssim_by_class[0]), np.mean(ssim_by_class[1])], \n",
        "               color=['#3498db', '#e74c3c'], alpha=0.7, edgecolor='black')\n",
        "axes[0, 0].axhline(np.mean(ssim_all), color='red', linestyle='--', linewidth=2, label='Overall')\n",
        "axes[0, 0].set_ylabel('Average SSIM')\n",
        "axes[0, 0].set_title('SSIM Comparison: Cat vs Dog')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "axes[0, 1].bar(['Cat', 'Dog'], [np.mean(psnr_by_class[0]), np.mean(psnr_by_class[1])], \n",
        "               color=['#3498db', '#e74c3c'], alpha=0.7, edgecolor='black')\n",
        "axes[0, 1].axhline(np.mean(psnr_all), color='red', linestyle='--', linewidth=2, label='Overall')\n",
        "axes[0, 1].set_ylabel('Average PSNR (dB)')\n",
        "axes[0, 1].set_title('PSNR Comparison: Cat vs Dog')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "axes[1, 0].scatter(ssim_all[cat_mask], psnr_all[cat_mask], alpha=0.5, s=30, label='Cat', color='#3498db')\n",
        "axes[1, 0].scatter(ssim_all[dog_mask], psnr_all[dog_mask], alpha=0.5, s=30, label='Dog', color='#e74c3c')\n",
        "axes[1, 0].set_xlabel('SSIM')\n",
        "axes[1, 0].set_ylabel('PSNR (dB)')\n",
        "axes[1, 0].set_title(f'SSIM vs PSNR by Class (corr={correlation:.3f})')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "quality_bins = ['Poor\\n(<0.75)', 'Fair\\n(0.75-0.80)', 'Good\\n(0.80-0.85)', 'Excellent\\n(>=0.85)']\n",
        "quality_counts = [\n",
        "    np.sum(ssim_all < 0.75),\n",
        "    np.sum((ssim_all >= 0.75) & (ssim_all < 0.80)),\n",
        "    np.sum((ssim_all >= 0.80) & (ssim_all < 0.85)),\n",
        "    np.sum(ssim_all >= 0.85)\n",
        "]\n",
        "colors = ['#e74c3c', '#f39c12', '#2ecc71', '#27ae60']\n",
        "axes[1, 1].bar(quality_bins, quality_counts, color=colors, alpha=0.7, edgecolor='black')\n",
        "axes[1, 1].set_ylabel('Number of Images')\n",
        "axes[1, 1].set_title('Image Quality Distribution')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_samples = 16\n",
        "random_indices = np.random.choice(len(X_test_normalized), n_samples, replace=False)\n",
        "\n",
        "fig, axes = plt.subplots(4, n_samples//2, figsize=(20, 10))\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "    row = (i // (n_samples//2)) * 2\n",
        "    col = i % (n_samples//2)\n",
        "    \n",
        "    axes[row, col].imshow(X_test_normalized[idx])\n",
        "    axes[row, col].set_title(f'{class_names[y_test[idx][0]]}', fontsize=9)\n",
        "    axes[row, col].axis('off')\n",
        "    \n",
        "    axes[row+1, col].imshow(test_predictions[idx])\n",
        "    ssim_val = ssim_all[idx]\n",
        "    psnr_val = psnr_all[idx]\n",
        "    color = 'green' if ssim_val >= 0.80 else 'orange' if ssim_val >= 0.70 else 'red'\n",
        "    axes[row+1, col].set_title(f'SSIM:{ssim_val:.3f}\\nPSNR:{psnr_val:.1f}dB', \n",
        "                               fontsize=8, color=color)\n",
        "    axes[row+1, col].axis('off')\n",
        "\n",
        "plt.suptitle(f'Random Sample Reconstructions (n={n_samples})', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if CONFIG['USE_ATTENTION']:\n",
        "    n_samples = 8\n",
        "    random_indices = np.random.choice(len(X_test_normalized), n_samples, replace=False)\n",
        "    \n",
        "    fig, axes = plt.subplots(3, n_samples, figsize=(20, 8))\n",
        "    \n",
        "    for i, idx in enumerate(random_indices):\n",
        "        axes[0, i].imshow(X_test_normalized[idx])\n",
        "        axes[0, i].set_title(f'{class_names[y_test[idx][0]]}', fontsize=9)\n",
        "        axes[0, i].axis('off')\n",
        "        \n",
        "        axes[1, i].imshow(test_predictions[idx])\n",
        "        axes[1, i].set_title(f'SSIM:{ssim_all[idx]:.3f}', fontsize=8)\n",
        "        axes[1, i].axis('off')\n",
        "        \n",
        "        diff = np.abs(X_test_normalized[idx] - test_predictions[idx])\n",
        "        diff_gray = np.mean(diff, axis=-1)\n",
        "        im = axes[2, i].imshow(diff_gray, cmap='hot', vmin=0, vmax=0.3)\n",
        "        axes[2, i].set_title('Error Map', fontsize=8)\n",
        "        axes[2, i].axis('off')\n",
        "    \n",
        "    axes[0, 0].set_ylabel('Original', fontsize=11, fontweight='bold', rotation=0, ha='right', va='center')\n",
        "    axes[1, 0].set_ylabel('Reconstructed', fontsize=11, fontweight='bold', rotation=0, ha='right', va='center')\n",
        "    axes[2, 0].set_ylabel('Attention\\nFocus', fontsize=11, fontweight='bold', rotation=0, ha='right', va='center')\n",
        "    \n",
        "    plt.colorbar(im, ax=axes[2, :], orientation='horizontal', fraction=0.05, pad=0.05, label='Error Magnitude')\n",
        "    plt.suptitle('Spatial Attention Visualization (Red = High Error/Attention)', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
